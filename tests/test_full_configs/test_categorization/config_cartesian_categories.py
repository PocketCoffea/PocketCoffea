# This config has been generated by the pocket_coffea CLI 0.9.4.
from pocket_coffea.utils.configurator import Configurator
from pocket_coffea.lib.cut_definition import Cut
from pocket_coffea.lib.cut_functions import get_nObj_min, get_nObj_eq, get_HLTsel, get_nPVgood, goldenJson, eventFlags
from pocket_coffea.parameters.cuts import passthrough
from pocket_coffea.parameters.histograms import *
from pocket_coffea.lib.categorization import StandardSelection, CartesianSelection, MultiCut

import workflow
from workflow import BasicProcessor

# Register custom modules in cloudpickle to propagate them to dask workers
import cloudpickle
import custom_cut_functions
cloudpickle.register_pickle_by_value(workflow)
cloudpickle.register_pickle_by_value(custom_cut_functions)

from custom_cut_functions import *
import os
localdir = os.path.dirname(os.path.abspath(__file__))

# Creating weights configuration
from pocket_coffea.lib.weights.common import common_weights

# Loading default parameters
from pocket_coffea.parameters import defaults
default_parameters = defaults.get_default_parameters()
defaults.register_configuration_dir("config_dir", localdir+"/params")

parameters = defaults.merge_parameters_from_files(default_parameters,
                                                    f"{localdir}/params/object_preselection.yaml",
                                                    f"{localdir}/params/triggers.yaml",
                                                   update=True)

#Creating custom weight
from pocket_coffea.lib.weights.weights import WeightLambda
import numpy as np



cfg = Configurator(
    parameters = parameters,
    datasets = {
        "jsons": ['datasets/datasets_cern.json'],
        "filter" : {
            "samples": ['TTTo2L2Nu', "DATA_SingleMuon"],
            "samples_exclude" : [],
            "year": ['2018']
        }
    },

    workflow = BasicProcessor,

    skim = [get_nPVgood(1), eventFlags, goldenJson], 

    preselections = [passthrough],
    categories = CartesianSelection(
        multicuts = [
            MultiCut(name="Njets",
                     cuts=[
                         get_nObj_eq(1, 30., "JetGood"),
                         get_nObj_eq(2, 30., "JetGood"),
                         get_nObj_min(3, 30., "JetGood"),
                     ],
                     cuts_names=["1j","2j","3j"]),
            MultiCut(name="Nbjet",
                    cuts=[
                         get_nObj_eq(0, 15., "BJetGood"),
                         get_nObj_eq(1, 15., "BJetGood"),
                         get_nObj_eq(2, 15., "BJetGood"),
                         get_nObj_min(3, coll="BJetGood"),
                     ],
                     cuts_names=["0b","1b","2b","3b"])
        ],
        common_cats = {
            "inclusive": [passthrough],
            "4jets_40pt" : [get_nObj_min(4, 40., "JetGood")]
        }
    ),

    weights = {
        "common": {
            "inclusive": ["genWeight","lumi","XS","pileup",
                          "sf_ele_id","sf_ele_reco",
                          "sf_mu_id","sf_mu_iso",
                          ]
       },
        "bysample": {
            "TTTo2L2Nu": {
                "bycategory": {
                    "2j_2b": ["sf_btag"],
                }
            }
        }
    },
    # Passing a list of WeightWrapper objects
    weights_classes = common_weights,

    variations = {
        "weights": {
            "common": {
                "inclusive": [ "pileup",
                               "sf_ele_id", "sf_ele_reco",
                               "sf_mu_id", "sf_mu_iso",
                               ],  
            },
            "bysample": {
                "TTTo2L2Nu": {
                    "bycategory": {
                        "2j_2b": ["sf_btag"]
                    }
            }
            }
        },
    },

    variables = {
        **ele_hists(),
        **jet_hists(),
        **count_hist("JetGood"),
        **count_hist("BJetGood"),
    },

    columns = {

    },
)
