# This config has been generated by the pocket_coffea CLI 0.9.4.
from pocket_coffea.utils.configurator import Configurator
from pocket_coffea.lib.cut_definition import Cut
from pocket_coffea.lib.cut_functions import get_nObj_min, get_nObj_eq, get_HLTsel, get_nPVgood, goldenJson, eventFlags
from pocket_coffea.parameters.cuts import passthrough
from pocket_coffea.parameters.histograms import *
from pocket_coffea.lib.categorization import StandardSelection, CartesianSelection, MultiCut
from pocket_coffea.lib.columns_manager import ColOut

import workflow
from workflow import BasicProcessor

# Register custom modules in cloudpickle to propagate them to dask workers
import cloudpickle
import custom_cut_functions
cloudpickle.register_pickle_by_value(workflow)
cloudpickle.register_pickle_by_value(custom_cut_functions)

from custom_cut_functions import *
import os
localdir = os.path.dirname(os.path.abspath(__file__))

# Creating weights configuration
from pocket_coffea.lib.weights.common import common_weights

# Loading default parameters
from pocket_coffea.parameters import defaults
default_parameters = defaults.get_default_parameters()
defaults.register_configuration_dir("config_dir", localdir+"/params")

parameters = defaults.merge_parameters_from_files(default_parameters,
                                                    f"{localdir}/params/object_preselection.yaml",
                                                    f"{localdir}/params/triggers.yaml",
                                                   update=True)

#Creating custom weight
from pocket_coffea.lib.weights.weights import WeightLambda
import numpy as np



cfg = Configurator(
    parameters = parameters,
    datasets = {
        "jsons": ['datasets/datasets_cern.json'],
        "filter" : {
            "samples": ['TTTo2L2Nu', "DATA_SingleEle"],
            "samples_exclude" : [],
            "year": ['2018']
        },
        "subsamples": {
            "TTTo2L2Nu": {
                "ele": [get_nObj_min(1, coll="ElectronGood"), get_nObj_eq(0, coll="MuonGood")],
                "mu":  [get_nObj_eq(0, coll="ElectronGood"), get_nObj_min(1, coll="MuonGood")],
            }
        }
    },

    workflow = BasicProcessor,
    workflow_options = {
    "dump_columns_as_arrays_per_chunk": "./columns"},
    
    skim = [get_nPVgood(1), eventFlags, goldenJson,
            get_HLTsel(primaryDatasets=["SingleEle"])], 

    preselections = [passthrough],
    categories = {
        "2btag": [get_nObj_min(2, coll="BJetGood")],
        "4jets": [get_nObj_min(4, minpt=30, coll="JetGood")],
    },

    weights = {
        "common": {
            "inclusive": ["genWeight","lumi","XS","pileup",
                          "sf_ele_id","sf_ele_reco",
                          "sf_mu_id","sf_mu_iso"
                          ],
            "bycategory": {
            },
       },
        "bysample": {
        }
    },
    # Passing a list of WeightWrapper objects
    weights_classes = common_weights,

    variations = {
        "weights": {
            "common": {
                "inclusive": [ "pileup",
                               "sf_ele_id", "sf_ele_reco",
                               "sf_mu_id", "sf_mu_iso",
                               ],
                "bycategory" : {
                }
            },
            "bysample": {
            }
        
        },
    },

    variables = {
    },

    columns = {
        "common": {
            "inclusive": [
                ColOut("JetGood", ["pt", "eta"], flatten=False),
            ],
        },
        "bysample": {
            "TTTo2L2Nu": {
                "bycategory": {
                    "2btag": [
                        ColOut("BJetGood", ["pt", "eta", "phi"], flatten=False),
                    ],
                    "4jets": [
                        ColOut("JetGood", ["pt", "eta", "phi"], flatten=False),
                    ],
                }
            }
        }
    },
)
